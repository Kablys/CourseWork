\documentclass{VUMIFInfKursinis}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{color}
\usepackage{hyperref}  % Nuorodų aktyvavimas
\usepackage{url}

%My personal additions
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes} 
\usepackage{booktabs} 



% Titulinio aprašas
\university{Vilniaus universitetas}
\faculty{Matematikos ir informatikos fakultetas}
\department{Informatikos katedra}
\papertype{Kursinis darbas}
\title{Dokomentų klasterizacija}
\titleineng{Document clustering}
\status{4 kurso 1 grupės studentas}
\author{Dominykas Ablingis}
% \secondauthor{Vardonis Pavardonis}   % Pridėti antrą autorių
\supervisor{lekt. Rimantas Kybartas}
\date{Vilnius \\ \the\year}

% Nustatymai
\setmainfont{Palemonas}   % Pakeisti teksto šriftą į Palemonas (turi būti įdiegtas sistemoje)
\bibliography{bibliografija} 

\begin{document}
%My macros

\newcommand{\LTandENG}[2]{#1 (angl. \textit{#2}) }
\newcommand{\BigO}[1]{$\mathcal{O}(#1)$}
\listoftodos[Notes]

\maketitle

\tableofcontents

\sectionnonum{Sąvokų apibrėžimai}
%Sutartinių ženklų, simbolių, vienetų ir terminų sutrumpinimų sąrašas (jeigu ženklų, simbolių, vienetų ir terminų bendras skaičius didesnis nei 10 ir kiekvienas iš jų tekste kartojasi daugiau nei 3 kartus).

\sectionnonum{Įvadas}
%Įvade apibūdinamas darbo tikslas, temos aktualumas ir siekiami rezultatai. Darbo įvadas neturi būti dėstymo santrauka. Įvado apimtis 1–2 puslapiai.
Šiais laikais kai kiekvienas žmogus turintis priėjimą prie interneto gali dalintis informacija, daugybė knygu yra skaitmenizuojamos kiekvieną dieną ir mokslo institucijos dalinasi savo moksline informacija, pasiekemos informacijos kiekis didėja su kiekviena diena ir pagrindinė problema nebėra informacijos trūkumas, o atradimas ko reikia. Tam spresti buvo ir yra kuriama ivairūs mechanizmai: paiškos varikliai\ldots Šiame darbe autorius nagrinės viena iš šios problemos sprendimo metodų, klasterizacijos algoritmus ir jų panaudojimą textinems dokumentams. %Klasterizacijos algoritmai priklauso neprižiūrimo mokymosi \textbf{tipui} ir pagrinde naudojami.
Dokomentų klasterizacijos panaudojimai:
\begin{itemize}
	\item Automatinis dokumentų organizavimas. Dažnai alternatyvus šios problemos sprendimas yra dokumentų \LTandENG{žymėjimas}{taging}.
	\item Temų \textbf{išgavimas}
	\item Greitas informacijos paiška ir filtravimas, ypač
\end{itemize}
Šiame darbe taip pat bus paminėtos kitos su dokumentu klasterizacija susijusios problemos ir ši informacija bus išdėstyta eilės tvarka kaip būtu sprendžiamos užduotys.
\begin{enumerate}
	\item Duomenų išgavimas iš skirtingų medijų
	\item Duomenų apdorojimas
	\item Algoritmai
	\item Algoritmų testavimas
	\item Rezultatų vizuoalizacija
\end{enumerate}


\section{Pagrindinė tiriamoji dalis}
%Pagrindinėje tiriamojoje dalyje aptariama ir pagrindžiama tyrimo metodika; pagal atitinkamas darbo dalis, nuosekliai, panaudojant lyginamosios analizės, klasifikacijos, sisteminimo metodus bei apibendrinimus, dėstoma sukaupta ir išanalizuota medžiaga.


\section{Duomenų išgavimas, apdorojimas ir pavertimas į patogia formą}
	Jeigu dirbame su iš anksto neparuoštu \LTandENG{duomenų rinkiniu}{data set}, reika pradėti nuo duomenų apdorojimo\cite{kadhim2014text}. Šiuo atveju duomenys yra dokumentai kurie gali būti pateikti įvairiais formatais: moksliniai darbai Latex formatu, internetiniai puslapiai html fotmatu, elektroninės kngyos \ldots Šiuos dokumentus reikia transliuoti į patogesnią analizei formą. Taip pat dažnai susiduriant su žmogišku tekstu reikia ji paildomai apdoroti. Dažnai išemami stop words (nekaitomos kalbos dalys) (nebent atilekama frazių analizė) ir ženklai (!?\ldots), žodžiai pakeičiami į bendrinię formą, kad supaprastini apdorojamą teksta neprarandant gilesnės teksto minties. 

\subsection{Duomenų išgavimas}
Informacijos išgavimas iš interneto ir kitų šaltinių
\subsubsection{XML/HTML dokumentai}
XML atvėju \texttt{<tag>Content</tag>} tag galime interpretuoti kaip kintamajį. Galima interpretuoti kaip  kintamoji Content kaip kintamojo reikšmę, arba tag kaip teksto anotacija. Bet tai negalioja html atveju tagai Skirti nurodyti svetainės išdėstymą. Pavyzdžiui <h1> dažniausiai reiškia pavadinimą ar antrašnę ir XML atvėju turbūt būtu <title>. Taip pat Interneto svetainės turi  kitos tekstinės informacijos kaip navigacija, komentarai, kontaktai ir panašiai. Šia problema sprendžiam keliais žingsniais:
Pirma galime pasinaudoti tuo kad HTML yra DOM … todėl tai yra medžio struktūra. Supaprastinti darba galima apdorojant tik specifines šakas, bet tarp skirtingu svetainių šis medis atrodys skirtingai, taigi to pakaks tik dalinai
Kurkas paprastesnis būdas pasinaudoti statisniu metodu (Finn’s method). Atskireme tagus į skirtus tekstui (<bold>, <italic>\ldots) ir neskirtus (<head>, <body>\ldots). Tada stebime tagų (neskirtu tekstui) pasiskirstyma puslapyje lyginat su tekstu, ten kur ju daug galime numanyti kad tai nera pagrindinis puslapio turinys ir vice versa. Tai pavaizdavus grafike pamatytume išsilyginima
\subsubsection{PDF}
\LTandENG{PDF}{Portable Document Format} Dokumentų formatas skirtas lengvam dokumentų dalinimuisi tarp skirtingų sistemų. Nors PDF yra sudėtingas ir suspaustas formatas, bet palygint lengvai galima išgauti textinę informaciją.%\todonotes{Detalesnis aprasymas ir budai išgauti tekstą}
\subsubsection{Tex}
Tex yra dokumentų maketavimo kalba ypač dažnai naudojama matematikos, fizikos ir kommpiuterių mokslo srityse. Dali moksliniu darbų ir knygų galima prieti netik PDF bet ir autorių rašta Latex versija.
\subsubsection{Elektroninių knygų formatai}
\begin{itemize}
	\item ePub
	\item MOBI
	\item AZW
\end{itemize}


\subsection{Duomenų apdorojimas}
\subsubsection{Tokenization --- teksto išskaldymas į reikšmingas dalis}
Žodžius, frazes ir t.t.\  vadinamas token. Vėliau šie žodžiai bus naudojami kaip ideksai žodyne. Tekstų tokenizacija yra vis dar aktyviai tiriama sritis, ypač kalboms kuriose nėra aiškių žodžių ribų (\url{https://en.wikipedia.org/wiki/Scriptio_continua}). Taip pat problematiški žodžiai su ženkalais viduje: I.B.M.\; pre-diabetes. Tokiais atvėjais netinka nei atskirti nei sujungti nes abejais atvėjais prarandama prasmė ir sukuremi netikslūs token’ai. Yra keli sprendimai: vienas padaryti abu (dalinti ir jungti) tokiu butu atsiranda daugiau triukšmo duomenyse, bet tai neturetu buti problema jeigu tvarkingi svoriai. 
Morfologinė variacija. Problema su žodžiais kur viena šaknis gali turėti kelias skirtingas prasmes. Arabų kalba ypač sudėtinga šituo atžvilgiu nes turi palygint mažai šaknų, bet labai daug variacijų. Pokyčiai gali būti prieš, po ir pačioje šaknyje.

\subsubsection{Stemming --- žodžio šaknies išgavimas.}
Dažnai programos (angliškai vadinamos stemmers) gauna žodį ir gražina jo šaknį. Egzistuoja keli implementacijos būdai: 
\\Naudojant parengtas taisykles ir išimčių žodynus. Šiam metodui implementuoti reikia kalbos eksperto kurio pagalba būtu suprogramuojamos visos taisyklės ir išimtys. Šis metodas veikia gerai bet reikalauja daug laiko, yra sudetingas ir sunkiai apibendrinamas.
\\Kitas būdas raidžių n-gramos, panašiuose žodžiuose panašios n-gramos. Standartiškai Europinėms kalboms $n = 4$. Stemming’as gali ivykti skirtinguose apdorojimo etapuose priklausomai nuo užduoties.

\subsubsection{Nereikšmingų žodžių pašalinimas}
\LTandENG{Nereikšmingi žodžiai}{stop-words} --- tai tokie žodžiai (įvardžiai, prielinksniai, jungtukai ir pan.) kurie jungia reikšmingas teksto dalis. Reikia atkreipti dėmėsį, kad skirtingos sritys gali turėti skirtingus stop-word (pvz internete žodis “click”). Taip pat kai kurios frazės gali būti sudarytos iš stop-word ir turėti prasmę (“to be or not to be”). Šiai problemai naudojami specifinės kalbos ir srities žodynų junginys.%\todo[inline]{Paieskok lietuvisku variantu}

\subsubsection{Sinonimiškumas ir Polisemija}
Indexų pavyzdžiai: Wordnet, MeSH, taip pat yra daug statistinių metodų. Kartais prašoma vartotojų Prašoma nurodyti kurią iš sinonimo reikšmių jie turėjo omeny arba vertinti paieškos rezultatus nurodant kurie atitinka o kurie ne, tokiu butu paieškos problema paversti į supervised learning problemą (relevance feedback).

\subsection{Pavertimas į patogia formą}
4. Computing term frequencies or tf-idf
After pre-processing the text data, we can then proceed to generate features. For document clustering, one of the most common ways to generate features for a document is to calculate the term frequencies of all its tokens. Although not perfect, these frequencies can usually provide some clues about the topic of the document. And sometimes it is also useful to weight the term frequencies by the inverse document frequencies. See tf-idf for detailed discussions.

\section{Algoritmai}
Klasterizacijos algoritmai yra skirstomi į šias rūšis:
Klasterizacijos algoritmai gali padėti atsakyti į klausimus:
\begin{itemize}
	\item Ar ir kiek sub-populiaciju turi mano duomenys
	\item Kokio dydzio tos populiacijos
	\item Ar sub-populiacijos turi bendrų savybių
	\item Ar sub-populiacijos yra vientisos ar jas galima papildomai išskaldyti
\end{itemize}
Klasteringo algoritmai skirstomi į šiuos tipus:
\begin{itemize}
	\item monothetic – visi populiacijos nariai turi kažkokia bendrą savybę (vyrai nuo 20 iki 25 metų amžiaus)
		\\polythetic – nariai yra panšūs, bet neturi konkrečios bendros savybės (kai atstumas tarp narių nurodo priklausomybę grupei)
	\item \LTandENG{kieti}{hard} klasteriai – kai grupės neturi bendrų narių. Kartais gali atsirasti atėjai kai elementas “matematiškai” gali priklausyti ne vienai grupei, bet toks atvėjis yra retas.
		\\\LTandENG{minkšti}{soft} klasteriai – kai grupės gali turėti bendrų narių. Tokiu atveju galime nagrinėti kaip konkretus elementas priklauso skirtingoms grupėms ir kaip gerai jas atitinka.
	\item \LTandENG{plokšti}{flat} – kai elementai suskirstomi į grupes, kurios viena kitai yra lygios.
		\\\LTandENG{herarkiški}{hierarchical}Hierarchical (herarkiškas) (taxonomy) – Kai grupė gali būti sudaryta iš kelių “konkretesnių” grupių. Pvz.\ retryveris $\,\to\,$ šuo $\,\to\,$ žinduolis $\,\to\,$ gyvūnas
\end{itemize}
Šiame skyriuje apžvelksiu algoritmų:

\begin{table}[H]\footnotesize
  \centering
  \caption{Lentelės pavyzdys}    % Antraštė įterpiama prieš lentelę
  {\begin{tabular}{lccc} 
	\toprule
	Algoritmas & \multicolumn{3}{c}{Tipas} \\
	\midrule
	K-mean  & hard    & flat & polythetic \\ %\midrule
	Hierarchical  & hard    & x & x       \\
	\bottomrule
  \end{tabular}}
\end{table}

\subsection{K-means}
\LTandENG{K-vidurkių}{K-mean} algoritmas suskirsto duomenis į nurodytą ($ k $) klasterių. \[ \underset{\mathbf{S}} {\operatorname{\arg \min}}  \sum_{i=1}^{k} \sum_{\mathbf x \in S_i} \left\| \mathbf x - \boldsymbol\mu_i \right\|^2 \]
Praktikoje dažniausiai naudojamas duodama $n$ vektroių (su $d$ dimensijų) ir numeris $k$.  Sustatome $k$ centroidų $c$ į atsitiktines vietas.
\begin{enumerate}
	\item Kiekvienam taskui (vektoriui) randame artimiausia c
	\item Kiekviena centroida pakeiti taip kad jis geriau atitiktu jam priskirtą klusterį (sumažinti atstuma iki visų taškų arba kitaip tariant rasti taškų centrą). Tada eini i žingsni  1.\ %TODO add proper reference
	tol kol visi klusteriai išlieka vienodi.
\end{enumerate}
\BigO{iteracijos*K*n*d} produce hard, flat, polythetic cluster. 

%\subsection{mixture models}
\subsection{Hierarchinis klasterizavimas}
\LTandENG{Hierarchical clustering}{Hierarchinis klasterizavimas} Šis metodas neskirsto dokumentu į konkrečias gr, bet vietoj to suskirsto dokuemntus į herarhicja. Tam atlikti reikiai būdo kaip matuoti dokumentų panašumą. 

\BigO{n^3}

\subsection{Expectation maximization}
\subsection{Farthest First}
\subsection{Density Based Spatial Clustering}
\subsection{Fuzzy k-means}
\subsection{Dirichlet}

\subsection{Affinity Propagation}
\subsection{Mean Shift}
\subsection{Spectral clustering}
\subsection{Birch}


\subsection{Binarization of consensus partition matrices}
\subsection{Canopy clustering algorithm}
\subsection{Cluster-weighted modeling}
\subsection{Cobweb}
\subsection{Complete-linkage clustering}
\subsection{Constrained clustering}
\subsection{CURE data clustering algorithm}
\subsection{Data stream clustering}
\subsection{DBSCAN}
\subsection{FLAME clustering}
\subsection{Fuzzy clustering}
\subsection{Hoshen–Kopelman algorithm}

\subsection{Latent Dirichlet allocation}
Latent Dirichlet allocation (toliau LDA, nesumaišyti su Linear discriminant analysis, kas yra kitas mašininio mokymosi metodas). Yra kurkas sudetingesnis dokumentu analizavimo metodas. Kartais priskiremas atskirai algoritmu klasei Topic modeling, kuri bando ne grupuoti duomenis o suteigti jiems temas. Palyginant su praeitais metodais dokumentai turėjo priklausyti vienai iš klasterių ar jų herarkijai, bet dokumentas gali turėti kelias temas. 
% Reikia perkelti ir tiksliau apibrėžti ką būtent gražina.	
Todėl LDA gražina ne sugrupuotus duomenis, o pasiskirstymą kiek kokių temų turi kiekvienas dokumentas  

\section{Algoritmų testavimas}
Viena iš fundamentalių neprižiūrimo mokymosi problemų yra modelių testavimas. Skirtingai nei „prižurimame mokymasi“ kur svarbu atdidėti dali duomenų su kuriais nėra mokomasi o tik testuojama sugeneruoti modeliai, „neprižiurimame mokymasi“ mes to nelgalim atlikti\ldots Bet egzsituoja keltatas metodu kaip galima patikrinti sudarytus klasterius.
\begin{itemize}
	\item Pirma galima sugeneruotus klasterius leisti tikrinti \textbf{žmonėms }. Tam yra keli būdai. Galima tiesiog duoti sugeneruotus klasterius ir bandyti nuspresti ar jie tinkami. Taipat galima parainkti du atsitiktinius dokumentus ir spėti ar jie turėtu būti viename ar atskiruose klasteriuose, ir tada palyginti su kompiuterio sugeneruotu rezultatu. 
	\item Taip yra metodų kaip atlikti testavimą automatiškai. Vienas jų paimti 2(ar daugiau) dokumentus iš skirtingų klasterių ir apkeisti juos vietomis, tada patikrinti klasteriu //stipruma. Tai atlike dokybe kartų galime spręsti kaip sėkmingai sekėsi klasterizacija, jeigu apmainant jų kokybė nukrito tai reikškia, kad dokumentai sėkmingai suklaserizuoti, bet jeigu nesikeite tai reiške, kad klasteriai mažai vienas nuo kito skiresi ir klasreizacija nesekminga.
\end{itemize}

\section{Rezultatų vizuoalizacija}
Dažnai norėdami geriau pažinti (ar testuoti) klasterizacijos rezultatus mes galime juo vizuolizuoti. Vizulaizacijos gali buti įvairios ir dažnai priklauso nuo algoritmo rūšies, bet dažniausiai naudojama \textbf{point cloud} vizualizacijos. Jose matosi pagal kokius parameturs (ašis) buvo klasterizuojama ir kaip atrodo sudaryti klasteriai.Taip pat galima pridėti papildomų indikatorių, priklausomų nuo algoritmo. Pavyzdžiui klasteriams sudarytiems k-means metodu galima nubraižyti atitinkamus „centrinius taškusn“.

\sectionnonum{Išvados}
%Išvadose ir pasiūlymuose, nekartojant atskirų dalių apibendrinimų, suformuluojamos svarbiausios darbo išvados, rekomendacijos bei pasiūlymai.

\printbibliography[heading=bibintoc] % Literatūros šaltiniai aprašomi
% bibliografija.bib faile. Šaltinių sąraše nurodoma panaudota literatūra,
% kitokie šaltiniai. Abėcėlės tvarka išdėstoma tik darbe panaudotų (cituotų,
% perfrazuotų ar bent paminėtų) mokslo leidinių, kitokių publikacijų
% bibliografiniai aprašai (šiuo punktu pasirūpina LaTeX). Aprašai pateikiami
% netransliteruoti.

\appendix  % Priedai
% Prieduose gali būti pateikiama pagalbinė, ypač darbo autoriaus savarankiškai
% parengta, medžiaga. Savarankiški priedai gali būti pateikiami kompiuterio
% diskelyje ar kompaktiniame diske. Priedai taip pat vadinami ir numeruojami.
% Tekstas su priedais siejamas nuorodomis (pvz.: \ref{img:mlp}).

\end{document}
